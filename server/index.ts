/**
 * @file /server/index.ts
 * @description ğŸš€ é›¶ä»£ç  AI é¡µé¢ç”Ÿæˆå™¨åç«¯ (LangChain.js v0.3+ ä¿®æ­£ç‰ˆ + å…¨é¢é”™è¯¯è°ƒè¯•æ—¥å¿—)
 */

import express from "express";
import cors from "cors";
import path from "path";
import { readFileSync } from "fs";
import dotenv from "dotenv";
import { ChatOpenAI } from "@langchain/openai";
import { JsonOutputParser } from "@langchain/core/output_parsers";
import { RunnableSequence } from "@langchain/core/runnables";
import { HumanMessage, SystemMessage } from "@langchain/core/messages";
import type { Component } from "../src/editor/stores/components";

// --- 1. ç¯å¢ƒä¸é…ç½®åˆå§‹åŒ– ---

dotenv.config({ path: path.resolve(process.cwd(), ".env") });

const app = express();
const port = 3001;
app.use(cors());
app.use(express.json({ limit: "10mb" }));

// --- 2. åŠ è½½ AI ä¸Šä¸‹æ–‡æ–‡ä»¶ ---

function loadDynamicData(): {
  materialsListJson: string;
  schemaExampleJson: string;
} {
  try {
    const materialsPath = path.resolve("server/template/materials.json");
    const schemaExamplePath = path.resolve(
      "server/template/lowcode-schema.json"
    );

    const materialsListJson = readFileSync(materialsPath, "utf-8");
    const schemaExampleJson = readFileSync(schemaExamplePath, "utf-8");

    if (!materialsListJson || !schemaExampleJson) {
      throw new Error("ä¸Šä¸‹æ–‡æ–‡ä»¶ä¸ºç©ºæˆ–æ— æ•ˆã€‚");
    }

    console.log("[AI Server] âœ… åŠ¨æ€ä¸Šä¸‹æ–‡åŠ è½½æˆåŠŸ (ç‰©æ–™åº“, SchemaèŒƒä¾‹)");
    return { materialsListJson, schemaExampleJson };
  } catch (error) {
    console.error("âŒ åŠ è½½åŠ¨æ€ä¸Šä¸‹æ–‡å¤±è´¥:", error);
    throw new Error("æœåŠ¡å™¨é…ç½®é”™è¯¯ï¼šæ— æ³•åŠ è½½ AI ä¸Šä¸‹æ–‡æ–‡ä»¶ã€‚");
  }
}

const { materialsListJson, schemaExampleJson } = loadDynamicData();

// --- 3. æ¨¡å‹ä¸è§£æå™¨åˆå§‹åŒ– ---

const baseUrl = process.env.OPENAI_BASE_URL || "https://api.openai.com/v1";

const visionModel = new ChatOpenAI({
  model: "gpt-4o-mini",
  temperature: 0.2,
  apiKey: process.env.OPENAI_API_KEY,
  configuration: { baseURL: baseUrl },
});

const generationModel = new ChatOpenAI({
  model: "gpt-4o-mini",
  temperature: 0,
  apiKey: process.env.OPENAI_API_KEY,
  configuration: { baseURL: baseUrl },
});

const intentParser = new JsonOutputParser();
const schemaParser = new JsonOutputParser<Component[]>();

// --- 4. é˜¶æ®µä¸€ï¼šæ„å›¾è¯†åˆ«é“¾ ---

const intentChain = RunnableSequence.from([
  async (input: { text: string; image_data: string | null }) => {
    const messages = [
      new SystemMessage(`
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å‰ç«¯ UI è®¾è®¡å¸ˆå’Œä½ä»£ç æ¶æ„å¸ˆã€‚
ä»»åŠ¡ï¼šåˆ†æç”¨æˆ·æä¾›çš„æ–‡æœ¬æè¿°å’Œï¼ˆå¯é€‰ï¼‰UI æˆªå›¾ï¼Œè¾“å‡ºä¸€ä¸ªç»“æ„åŒ–çš„ä¸­é—´æ„å›¾ JSONã€‚
è¾“å‡ºæ ¼å¼ï¼š{ "description": string, "layout": object, "components": array }
è§„åˆ™ï¼šè¾“å‡ºå¿…é¡»æ˜¯çº¯ JSONï¼Œä¸å« Markdownã€æ³¨é‡Šæˆ–ä»£ç å—ã€‚
`),
      new HumanMessage(
        `è¯·æ ¹æ®ä»¥ä¸‹å†…å®¹ç”Ÿæˆâ€œä¸­é—´æ„å›¾â€ JSONï¼š\n\n"${input.text}"`
      ),
    ];

    if (input.image_data) {
      messages.push(
        new HumanMessage({
          content: [
            { type: "text", text: "ä»¥ä¸‹æ˜¯é¡µé¢æˆªå›¾ï¼š" },
            {
              type: "image_url",
              image_url: { url: input.image_data },
            },
          ],
        })
      );
    }
    return messages;
  },

  // --- æ¨¡å‹è°ƒç”¨é˜¶æ®µ ---
  async (messages) => {
    try {
      console.log("ğŸ§  è°ƒè¯•ä¿¡æ¯: æ­£åœ¨è°ƒç”¨é˜¶æ®µä¸€æ¨¡å‹");
      console.log("ğŸ”‘ OPENAI_BASE_URL =", baseUrl);
      console.log(
        "ğŸ”‘ OPENAI_API_KEY (å‰5ä½) =",
        process.env.OPENAI_API_KEY?.slice(0, 5) || "æœªå®šä¹‰"
      );
      console.log("ğŸ§¾ æ¶ˆæ¯æ•°é‡ =", messages.length);

      const response = await visionModel.invoke(messages);
      console.log("âœ… æ¨¡å‹åŸå§‹å“åº”å¯¹è±¡:", response);

      const content = response?.content ?? null;
      if (!content) throw new Error("é˜¶æ®µä¸€è¾“å‡ºä¸ºç©º");

      console.log("ğŸ§© æ¨¡å‹è¾“å‡ºå†…å®¹é¢„è§ˆ:", content.slice(0, 150));
      return { content }; // âœ… ç¡®ä¿è¿”å›æ ‡å‡†ç»“æ„
    } catch (err: any) {
      console.error("âŒ é˜¶æ®µä¸€æ¨¡å‹è°ƒç”¨å¤±è´¥:", err.message || err);
      throw err;
    }
  },

  async (aiMessage) => {
    try {
      const parsed = await intentParser.invoke(aiMessage.content);
      return parsed;
    } catch (err) {
      console.error("âŒ é˜¶æ®µä¸€ JSON è§£æå¤±è´¥: æ¨¡å‹è¾“å‡ºéçº¯ JSON");
      console.error("ğŸª¶ åŸå§‹è¾“å‡º:", aiMessage?.content);
      throw err;
    }
  },
]);

// --- 5. é˜¶æ®µäºŒï¼šSchema ç”Ÿæˆé“¾ ---

const schemaGenerationChain = RunnableSequence.from([
  async (input: { user_intent_json: string }) => {
    const systemPrompt = `
ä½ æ˜¯ä¸€ä¸ªä½ä»£ç å¹³å° Schema ç”Ÿæˆå¼•æ“ã€‚
ä»»åŠ¡ï¼šæ ¹æ®â€œé¡µé¢æ„å›¾ JSONâ€å’Œâ€œç‰©æ–™åº“â€ç”Ÿæˆ Component[] JSONã€‚
ä¸¥æ ¼è¾“å‡ºåˆæ³• JSON æ•°ç»„ï¼Œæ— è§£é‡Šã€æ— ä»£ç å—ã€‚

interface Component {
  id: number;
  name: string;
  desc: string;
  props: any;
  styles?: object;
  parentId?: number;
  children?: Component[];
}

ã€ç‰©æ–™åº“ã€‘
${materialsListJson}

ã€é»„é‡‘æ ‡å‡†èŒƒä¾‹ã€‘
${schemaExampleJson}
`;
    return [
      new SystemMessage(systemPrompt),
      new HumanMessage(
        `ã€ç”¨æˆ·æ„å›¾ã€‘\n${input.user_intent_json}\n\nè¯·ä¸¥æ ¼è¾“å‡º Component[] JSONï¼š`
      ),
    ];
  },

  async (messages) => {
    try {
      console.log("ğŸ§  è°ƒè¯•ä¿¡æ¯: æ­£åœ¨è°ƒç”¨é˜¶æ®µäºŒæ¨¡å‹");
      const response = await generationModel.invoke(messages);
      console.log("âœ… é˜¶æ®µäºŒåŸå§‹å“åº”:", response);

      const content = response?.content ?? null;
      if (!content) throw new Error("é˜¶æ®µäºŒè¾“å‡ºä¸ºç©º");

      return { content };
    } catch (err: any) {
      console.error("âŒ é˜¶æ®µäºŒæ¨¡å‹è°ƒç”¨å¤±è´¥:", err.message || err);
      throw err;
    }
  },

  async (aiMessage) => {
    try {
      const parsed = await schemaParser.invoke(aiMessage.content);
      return parsed;
    } catch (err) {
      console.error("âŒ é˜¶æ®µäºŒ JSON è§£æå¤±è´¥: æ¨¡å‹è¾“å‡ºéçº¯ JSON");
      console.error("ğŸª¶ åŸå§‹è¾“å‡º:", aiMessage?.content);
      throw err;
    }
  },
]);

// --- 6. ä¸»ç®¡é“ç»„åˆ ---

const mainChain = RunnableSequence.from([
  intentChain,
  async (intentJson) => {
    console.log("\nğŸ§© é˜¶æ®µä¸€ç»“æœ (ä¸­é—´æ„å›¾):\n");
    console.dir(intentJson, { depth: null });
    return { user_intent_json: JSON.stringify(intentJson, null, 2) };
  },
  schemaGenerationChain,
]);

// --- 7. API è·¯ç”±å®šä¹‰ ---

app.post("/api/generate-page", async (req, res) => {
  try {
    const { text, image } = req.body;
    if (!text && !image) {
      return res.status(400).json({ message: "è¯·è¾“å…¥æè¿°æˆ–ä¸Šä¼ å›¾ç‰‡" });
    }

    const input = {
      text: text || "è¯·åˆ†æè¿™å¼ å›¾ç‰‡å¹¶ç”Ÿæˆé¡µé¢",
      image_data: image || null,
    };

    console.log("\nğŸš€ æ”¶åˆ°è¯·æ±‚ï¼š", input.text.slice(0, 100));

    const finalSchema = await mainChain.invoke(input);

    console.log(
      "\nâœ… é˜¶æ®µäºŒç»“æœ (æœ€ç»ˆ Schema JSON):\n",
      JSON.stringify(finalSchema, null, 2)
    );

    res.status(200).json(finalSchema);
  } catch (error: any) {
    console.error("âŒ AI ç®¡é“æ‰§è¡Œå¤±è´¥:", error);
    res.status(500).json({
      message: "AI ç”Ÿæˆå¤±è´¥",
      reason: error.message?.includes("è§£æ")
        ? "æ¨¡å‹è¾“å‡ºéçº¯ JSON"
        : error.message || "æœªçŸ¥é”™è¯¯",
      stack: process.env.NODE_ENV === "development" ? error.stack : undefined,
    });
  }
});

// --- 8. å¯åŠ¨æœåŠ¡å™¨ ---

app.listen(port, () => {
  console.log(`[AI Server] âœ… OpenAI åç«¯å¯åŠ¨æˆåŠŸï¼šhttp://localhost:${port}`);
});
